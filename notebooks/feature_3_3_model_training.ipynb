{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f542d8ce",
   "metadata": {},
   "source": [
    "# Feature 3.3 — Model Training (Churn + CLV)\n",
    "\n",
    "This notebook trains baseline models for churn (classification) and CLV (regression) with a synthetic fallback. Replace synthetic loaders with Delta/Spark reads when available.\n",
    "\n",
    "Artifacts: metrics CSVs, ROC/PR curves, calibration plot, feature importances, serialized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "import os, sys, math, json, random, time, pathlib, warnings\n",
    "import numpy as np, pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "SEED = int(os.getenv('SEED', '42'))\n",
    "np.random.seed(SEED); random.seed(SEED)\n",
    "OUT_DIR = os.getenv('OUT_DIR', 'artifacts/feature_3_3')\n",
    "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print('SEED', SEED, 'OUT_DIR', OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b576570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic fallback data generator (binary churn + positive CLV)\n",
    "def make_synthetic(n=5000, p=20, churn_rate=0.18, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = rng.normal(size=(n,p))\n",
    "    # churn logits depend on first 3 features\n",
    "    logits = 0.6*X[:,0] - 0.4*X[:,1] + 0.8*X[:,2] - 0.2\n",
    "    probs = 1/(1+np.exp(-logits))\n",
    "    probs = 0.5*probs + 0.5*churn_rate  # mix-in base rate\n",
    "    y_churn = rng.binomial(1, np.clip(probs, 0, 1))\n",
    "    # CLV depends on features with noise, non-negative\n",
    "    y_clv = np.maximum(0, 200 + 30*X[:,0] + 20*X[:,1] + 5*rng.normal(size=n))\n",
    "    cols = [f'f{i}' for i in range(p)]\n",
    "    df = pd.DataFrame(X, columns=cols)\n",
    "    df['churn'] = y_churn\n",
    "    df['clv'] = y_clv\n",
    "    return df\n",
    "\n",
    "df = make_synthetic()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8298e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/valid/test split using fixed seeds\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = [c for c in df.columns if c.startswith('f')]\n",
    "X = df[features].values\n",
    "y_cls = df['churn'].values\n",
    "y_reg = df['clv'].values\n",
    "X_train, X_tmp, y_train_cls, y_tmp_cls = train_test_split(X, y_cls, test_size=0.4, random_state=SEED, stratify=y_cls)\n",
    "X_valid, X_test, y_valid_cls, y_test_cls = train_test_split(X_tmp, y_tmp_cls, test_size=0.5, random_state=SEED, stratify=y_tmp_cls)\n",
    "_, X_tmp2, _, y_tmp2 = train_test_split(X, y_reg, test_size=0.4, random_state=SEED)\n",
    "X_valid_reg, X_test_reg, y_valid_reg, y_test_reg = train_test_split(X_tmp2, y_tmp2, test_size=0.5, random_state=SEED)\n",
    "X_train_reg = X_train; y_train_reg = y_reg[:len(X_train)]  # simple alignment for demo\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baselines\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Churn baselines\n",
    "p_base = y_train_cls.mean()\n",
    "auc_base = roc_auc_score(y_test_cls, np.full_like(y_test_cls, p_base, dtype=float))\n",
    "aupr_base = average_precision_score(y_test_cls, np.full_like(y_test_cls, p_base, dtype=float))\n",
    "\n",
    "# CLV baseline (mean)\n",
    "rmse_base = math.sqrt(mean_squared_error(y_test_reg, np.full_like(y_test_reg, y_train_reg.mean(), dtype=float)))\n",
    "mae_base = mean_absolute_error(y_test_reg, np.full_like(y_test_reg, y_train_reg.mean(), dtype=float))\n",
    "print('Baselines:', dict(auc_base=auc_base, aupr_base=aupr_base, rmse_base=rmse_base, mae_base=mae_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train churn Logistic Regression with calibration\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)\n",
    "cal_lr = CalibratedClassifierCV(lr, cv=5, method='isotonic')\n",
    "cal_lr.fit(X_train, y_train_cls)\n",
    "\n",
    "probs_test = cal_lr.predict_proba(X_test)[:,1]\n",
    "auc = roc_auc_score(y_test_cls, probs_test)\n",
    "aupr = average_precision_score(y_test_cls, probs_test)\n",
    "acc = accuracy_score(y_test_cls, (probs_test>=0.5).astype(int))\n",
    "print('Churn metrics:', dict(AUC=auc, AUCPR=aupr, ACC=acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap CI for AUC\n",
    "rng = np.random.default_rng(SEED)\n",
    "B=300\n",
    "idx = np.arange(len(y_test_cls))\n",
    "aucs=[]\n",
    "for _ in range(B):\n",
    "    s = rng.choice(idx, size=len(idx), replace=True)\n",
    "    aucs.append(roc_auc_score(y_test_cls[s], probs_test[s]))\n",
    "lo,hi = np.percentile(aucs,[2.5,97.5])\n",
    "print('AUC 95% CI:', lo, hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b15192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: ROC/PR and reliability\n",
    "import matplotlib.pyplot as plt\n",
    "fpr,tpr,_ = roc_curve(y_test_cls, probs_test)\n",
    "prec,rec,_ = precision_recall_curve(y_test_cls, probs_test)\n",
    "plt.figure(); plt.plot(fpr,tpr); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC'); plt.savefig(f'{OUT_DIR}/roc.png', dpi=150); plt.close()\n",
    "plt.figure(); plt.plot(rec,prec); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('PR'); plt.savefig(f'{OUT_DIR}/pr.png', dpi=150); plt.close()\n",
    "# Reliability diagram\n",
    "bins = np.linspace(0,1,11)\n",
    "digit = np.digitize(probs_test, bins)-1\n",
    "avg_p = [probs_test[digit==i].mean() if np.any(digit==i) else np.nan for i in range(10)]\n",
    "avg_y = [y_test_cls[digit==i].mean() if np.any(digit==i) else np.nan for i in range(10)]\n",
    "plt.figure(); plt.plot(avg_p, avg_y, 'o-'); plt.plot([0,1],[0,1],'--'); plt.xlabel('Pred prob'); plt.ylabel('Observed rate'); plt.title('Reliability'); plt.savefig(f'{OUT_DIR}/reliability.png', dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CLV RandomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=SEED, n_jobs=-1)\n",
    "rf.fit(X_train_reg, y_train_reg)\n",
    "pred_test = rf.predict(X_test_reg)\n",
    "rmse = math.sqrt(mean_squared_error(y_test_reg, pred_test))\n",
    "mae = mean_absolute_error(y_test_reg, pred_test)\n",
    "r2 = r2_score(y_test_reg, pred_test)\n",
    "print('CLV metrics:', dict(RMSE=rmse, MAE=mae, R2=r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ad1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation importance (fast approximation)\n",
    "from sklearn.inspection import permutation_importance\n",
    "pi_cls = permutation_importance(cal_lr, X_test, y_test_cls, n_repeats=5, random_state=SEED)\n",
    "pi_reg = permutation_importance(rf, X_test_reg, y_test_reg, n_repeats=5, random_state=SEED)\n",
    "imp_cls = pd.DataFrame({'feature':features,'importance':pi_cls.importances_mean}).sort_values('importance', ascending=False)\n",
    "imp_reg = pd.DataFrame({'feature':features,'importance':pi_reg.importances_mean}).sort_values('importance', ascending=False)\n",
    "imp_cls.to_csv(f'{OUT_DIR}/importance_churn.csv', index=False)\n",
    "imp_reg.to_csv(f'{OUT_DIR}/importance_clv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f08d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics and simple artifacts\n",
    "pd.DataFrame([{\n",
    "    'auc': auc, 'aupr': aupr, 'acc': acc,\n",
    "    'auc_base': auc_base, 'aupr_base': aupr_base\n",
    "}]).to_csv(f'{OUT_DIR}/churn_metrics.csv', index=False)\n",
    "pd.DataFrame([{\n",
    "    'rmse': rmse, 'mae': mae, 'r2': r2,\n",
    "    'rmse_base': rmse_base, 'mae_base': mae_base\n",
    "}]).to_csv(f'{OUT_DIR}/clv_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: MLflow logging if available\n",
    "try:\n",
    "    import mlflow\n",
    "    mlflow.set_experiment('feature_3_3_model_training')\n",
    "    with mlflow.start_run(run_name='churn_lr_calibrated'):\n",
    "        mlflow.log_params({'seed': SEED, 'model': 'LogisticRegression+Calibrated'})\n",
    "        mlflow.log_metrics({'auc': float(auc), 'aupr': float(aupr), 'acc': float(acc)})\n",
    "        mlflow.log_artifact(f'{OUT_DIR}/roc.png')\n",
    "        mlflow.log_artifact(f'{OUT_DIR}/pr.png')\n",
    "        mlflow.log_artifact(f'{OUT_DIR}/reliability.png')\n",
    "        mlflow.log_artifact(f'{OUT_DIR}/importance_churn.csv')\n",
    "    with mlflow.start_run(run_name='clv_rf'):\n",
    "        mlflow.log_params({'seed': SEED, 'model': 'RandomForestRegressor', 'n_estimators': 200})\n",
    "        mlflow.log_metrics({'rmse': float(rmse), 'mae': float(mae), 'r2': float(r2)})\n",
    "        mlflow.log_artifact(f'{OUT_DIR}/importance_clv.csv')\n",
    "except Exception as e:\n",
    "    warnings.warn(f'MLflow logging skipped: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc42618",
   "metadata": {},
   "source": [
    "Next steps: tune 1–2 hyperparameters, compute segment-wise metrics, and prepare the scoring contract preview for Feature 3.4."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
